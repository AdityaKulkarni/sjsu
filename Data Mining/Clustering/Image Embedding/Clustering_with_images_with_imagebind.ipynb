{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbiRrX3t1Ye2",
        "outputId": "e9ae4b7c-883d-4285-e0aa-ea2d01cff98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ImageBind'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 112 (delta 43), reused 33 (delta 33), pack-reused 51\u001b[K\n",
            "Receiving objects: 100% (112/112), 2.64 MiB | 5.24 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "Collecting git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
            "  Cloning https://github.com/facebookresearch/pytorchvideo.git (to revision 28fe037d212663c6a24f373b94cc5d478c8c1a1d) to /tmp/pip-req-build-mumeqpe4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorchvideo.git /tmp/pip-req-build-mumeqpe4\n",
            "  Running command git rev-parse -q --verify 'sha^28fe037d212663c6a24f373b94cc5d478c8c1a1d'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/pytorchvideo.git 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
            "  Running command git checkout -q 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
            "  Resolved https://github.com/facebookresearch/pytorchvideo.git to commit 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.6.7\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.6.3)\n",
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decord==0.6.0\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.6.7) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.6.7) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from decord==0.6.0) (1.23.5)\n",
            "Collecting av (from pytorchvideo==0.1.5)\n",
            "  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parameterized (from pytorchvideo==0.1.5)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting iopath (from pytorchvideo==0.1.5)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pytorchvideo==0.1.5) (3.2.1)\n",
            "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy)\n",
            "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath->pytorchvideo==0.1.5) (4.5.0)\n",
            "Collecting portalocker (from iopath->pytorchvideo==0.1.5)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.6.7) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.6.7) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.6.7) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.6.7) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.6.7) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.6.7) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->timm==0.6.7) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.6.7) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.6.7) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.6.7) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.6.7) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->timm==0.6.7) (1.3.0)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore, iopath\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=211199 sha256=09ec0aa1682beef6b319fed994ce9f84e391ca81f5140b99395407079277487d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/a0/a9/b2f1582cd6198b0425b645bdcce413a15f58d9cc3beee721d0\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=faf568b6797226f28ce86970300dfa6d35ea88a639aae19dc9af041675ed5a8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=827f61cbcd6e81f8b4dca7736b53b8ce46a1be2466a1232c22f2ba7deda007bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built pytorchvideo fvcore iopath\n",
            "Installing collected packages: wcwidth, yacs, portalocker, parameterized, ftfy, einops, decord, av, iopath, fvcore, timm, pytorchvideo\n",
            "  Attempting uninstall: wcwidth\n",
            "    Found existing installation: wcwidth 0.2.10\n",
            "    Uninstalling wcwidth-0.2.10:\n",
            "      Successfully uninstalled wcwidth-0.2.10\n",
            "Successfully installed av-11.0.0 decord-0.6.0 einops-0.7.0 ftfy-6.1.3 fvcore-0.1.5.post20221221 iopath-0.1.10 parameterized-0.9.0 portalocker-2.8.2 pytorchvideo-0.1.5 timm-0.6.7 wcwidth-0.2.12 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/ImageBind.git\n",
        "!pip install git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d timm==0.6.7 ftfy regex einops fvcore decord==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSiIAt1j2zVV",
        "outputId": "4b7bf2af-5ecf-4e46-9278-bb97c77148ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ImageBind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zo5QjqF1_TT",
        "outputId": "2d24bf2a-3ec0-4cfb-d0c1-4bc71c4a3204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ImageBind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from PIL import Image\n",
        "\n",
        "display(Image.open(\"../bird.jpeg\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "3ZD7q4c-2FMv",
        "outputId": "9f647d35-39c0-4ebf-dc6e-60467f6dd6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=187x125>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ImageBind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SleANab3Mul",
        "outputId": "bb3c63a0-9336-4e6f-877c-a7c00b70da67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ImageBind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from imagebind import data\n",
        "from models import imagebind_model\n",
        "from models.imagebind_model import ModalityType\n",
        "\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lQjeVhBv2w5U",
        "outputId": "66759f70-f4ca-4815-9fb1-9535ae23d7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = imagebind_model.imagebind_huge(pretrained=True)\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeMkZw7026zZ",
        "outputId": "2bd86d59-9c10-4b06-dc77-fb8c59bc5966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading imagebind weights to .checkpoints/imagebind_huge.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.47G/4.47G [00:29<00:00, 164MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageBindModel(\n",
              "  (modality_preprocessors): ModuleDict(\n",
              "    (vision): RGBDTPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 1280), requires_grad=True)\n",
              "      \n",
              "      (rgbt_stem): PatchEmbedGeneric(\n",
              "        (proj): Sequential(\n",
              "          (0): PadIm2Video()\n",
              "          (1): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 257, 1280), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (text): TextPreprocessor(\n",
              "      (pos_embed): tensor((1, 77, 1024), requires_grad=True)\n",
              "      (mask): tensor((77, 77), requires_grad=False)\n",
              "      \n",
              "      (token_embedding): Embedding(49408, 1024)\n",
              "    )\n",
              "    (audio): AudioPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 768), requires_grad=True)\n",
              "      \n",
              "      (rgbt_stem): PatchEmbedGeneric(\n",
              "        (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10), bias=False)\n",
              "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 229, 768), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (depth): RGBDTPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 384), requires_grad=True)\n",
              "      \n",
              "      (depth_stem): PatchEmbedGeneric(\n",
              "        (proj): Conv2d(1, 384, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
              "        (norm_layer): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 197, 384), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (thermal): ThermalPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 768), requires_grad=True)\n",
              "      \n",
              "      (rgbt_stem): PatchEmbedGeneric(\n",
              "        (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
              "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 197, 768), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (imu): IMUPreprocessor(\n",
              "      (pos_embed): tensor((1, 251, 512), requires_grad=True)\n",
              "      (cls_token): tensor((1, 1, 512), requires_grad=True)\n",
              "      \n",
              "      (imu_stem): PatchEmbedGeneric(\n",
              "        (proj): Linear(in_features=48, out_features=512, bias=False)\n",
              "        (norm_layer): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (modality_trunks): ModuleDict(\n",
              "    (vision): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (12): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (13): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (14): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (15): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (16): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (17): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (18): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (19): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (20): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (21): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (22): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (23): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (24): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (25): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (26): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (27): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (28): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (29): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (30): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (31): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (text): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (12): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (13): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (14): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (15): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (16): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (17): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (18): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (19): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (20): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (21): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (22): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (23): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (audio): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.009)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.018)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.027)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.036)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.045)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.055)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.064)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.073)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.082)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.091)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.100)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (depth): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (thermal): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (imu): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.140)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.280)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.420)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.560)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.700)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "  )\n",
              "  (modality_heads): ModuleDict(\n",
              "    (vision): Sequential(\n",
              "      (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=1280, out_features=1024, bias=False)\n",
              "    )\n",
              "    (text): SelectEOSAndProject(\n",
              "      (proj): Sequential(\n",
              "        (0): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "      )\n",
              "    )\n",
              "    (audio): Sequential(\n",
              "      (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=768, out_features=1024, bias=False)\n",
              "    )\n",
              "    (depth): Sequential(\n",
              "      (0): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=384, out_features=1024, bias=False)\n",
              "    )\n",
              "    (thermal): Sequential(\n",
              "      (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=768, out_features=1024, bias=False)\n",
              "    )\n",
              "    (imu): Sequential(\n",
              "      (0): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=512, out_features=1024, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (modality_postprocessors): ModuleDict(\n",
              "    (vision): Normalize()\n",
              "    (text): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=14.285714285714285,learnable=True, max_logit_scale=100)\n",
              "    )\n",
              "    (audio): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=20.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "    (depth): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "    (thermal): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=10.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "    (imu): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = {\n",
        "    ModalityType.VISION: data.load_and_transform_vision_data([\"../bird.jpeg\"], device),\n",
        "}\n",
        "\n",
        "with torch.no_grad():\n",
        "    embeddings = model(inputs)\n"
      ],
      "metadata": {
        "id": "DazD2Zo62-au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    \"Vision x Text: \",\n",
        "    embeddings[ModalityType.VISION]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaYUMlpw33-l",
        "outputId": "e9048a91-125c-4496-bfb3-a5c2e7c9a0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vision x Text:  tensor([[-0.0233, -0.0036,  0.0332,  ..., -0.0319,  0.0215, -0.0058]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}